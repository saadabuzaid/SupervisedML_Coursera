{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning Course by Andrew Ng on Coursera notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Supervised machine learning is giving the machine a data set with features(x) and their output (y) to build a model that can estimate/predict output (Y-hat) given features' values**\n",
    " This supervised machine learning model can be either:\n",
    "* **Regression model**: Predicts/estimates a value out of infinite number of possible values. \\\n",
    "        *e.g. Preidicting houses prices given features* \\\n",
    "        <br>\n",
    "* **Classification model**: Classifies the entry into small number of different classes/categores, can be numberical or non-numerical. \\\n",
    "        *e.g. classifying a picture whether it is a dog or a cat*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression:\n",
    "With linear regression, we are trying to build a model that is trying to recognise a numerical pattern with its given dataset (a set of data with features/inputs and actual outputs). This numerical pattern is a mathematical formula.\n",
    "\n",
    "**How can we know which formula to use?** \\\n",
    "This is where the machine learning comes in! The machine's objective is to learn what is the best mathematical to satisfy the output (y) with the given inputs/featues (x).\n",
    "\n",
    "**What does satisfying the output mean?** \\\n",
    "It means predicting the actual output value in the dataset using its inputs/features, and it does the same for all entries (Xs & Y) in the dataset. The better the formula is at satsfying all data entries from your dataset, the better your model is.\n",
    "\n",
    "In Calculus, a linear function is **f(x) = mx+c** where m is the slope of the function and a is the starting point where x = 0 (y-intercept) and f(x) is the output value y \\\n",
    "To simplify this function and to make it make sense in the course this is how a linear function is represnted: \\two\n",
    "**fw,b(x) = wx+b** where x is the feature's value, w is the slope (weight) and b is the y i\n",
    "\n",
    "![Linear regression example](/pictures/Linear%20regression%20example.png \"Linear regression graph example\")\n",
    "\n",
    "\n",
    "#### Classification:\n",
    "A Classification model will try to learn the best mathematical formula just like linear regression, but there is one difference. Linear regression will try to find a linear formual to satisfy outputs by predicting output value, but in a Classification model, the formula will by trying to draw a border line instead!\n",
    "This border line will create different zones in the graph, which are classes. Using features, if they fall into a specific zone, it means that they would be classified as the class/zone they fall in.\n",
    "\n",
    "![Classification example](/pictures/Classification%20example.png \"Classification graph example\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost function:\n",
    "A cost function is a way of testing your model/mathemtical forumula on how well it satisfy all entries in the dataset.\n",
    "There are multiple ways to calculate this cost function, but the course was mainly focused on the squared loss function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
